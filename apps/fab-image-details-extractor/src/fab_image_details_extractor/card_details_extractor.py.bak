# import logging
# import os
#
# import cv2
# import easyocr
# from pythonjsonlogger.json import JsonFormatter
#
# from fab_image_details_extractor.card_config import CardConfig, TextExtractor
#
# logger = logging.getLogger(__name__)
#
#
# def run():
#     log_level = os.environ["LOG_LEVEL"]
#     src_dir = os.environ["SRC_DIR"]
#     target_dir = os.environ["TARGET_DIR"]
#     init_logging(log_level)
#     pass
#
#
# def init_logging(log_level: str):
#     handler = logging.StreamHandler()
#     formatter = JsonFormatter(
#         "%(asctime)s %(levelname)s %(name)s %(message)s",
#         rename_fields={"levelname": "level", "asctime": "timestamp"},
#     )
#     handler.setFormatter(formatter)
#     logger.addHandler(handler)
#     logger.setLevel(log_level.upper())
#
#
# def get_unique_card_ids(dir: str) -> list[str]:
#     files = os.listdir(dir)
#     file_paths = [os.path.join(dir, file) for file in files]
#     return file_paths
#
#
# def extract_card_details(card_config: CardConfig, card_dir: str, card_id: str):
#     ocr_reader = easyocr.Reader(["en"])
#
#     extracts = []
#
#     for card_region_config in card_config["regions"]:
#         file_name = f"{card_id}__{card_region_config["name"]}.png"
#         img_path = os.path.join(card_dir, file_name)
#         if not os.path.exists(img_path):
#             continue
#         if card_region_config["text_extractor"] == TextExtractor.SIMPLE_INTEGER:
#             image = cv2.imread(img_path)
#             image = cv2.resize(image, (None), fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
#
#             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#
#             _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
#
#             results = ocr_reader.readtext(thresh, allowlist="0123456890")
#             text = " ".join([result[1] for result in results])
#
#             extracts.append({"name": card_region_config["name"], "text": text})
#
#     print(extracts)
#
#
# # class CardDetailsExtractor:
# #     card_config: CardConfig
# #
# #     def __init__(self, card_config: CardConfig):
# #         self.card_config = card_config
# #         self.ocr_reader = easyocr.Reader(["en"])
# #
# #     def extract_card_details(self, src_img: str):
# #         file_name = os.path.basename(src_img)
# #         file_base_name = file_name.split(".")[0]
# #         card_type = file_base_name.split("__")[1]
# #
# #         image = cv2.imread(src_img)
# #
# #         if card_type == "power":
# #             image = cv2.resize(image, (None), fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
# #
# #             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
# #
# #             _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
# #
# #             results = self.ocr_reader.readtext(thresh, allowlist="0123456890")
# #             text = " ".join([result[1] for result in results])
# #
# #         for region_config in self.card_config["regions"]:
# #             (x1, y1, x2, y2) = self.get_bounding_box_abs_positions(region_config, image)
# #
# #             roi = image[y1:y2, x1:x2]
# #
# #             if region_config["text_extractor"] == TextExtractor.SIMPLE_INTEGER:
# #                 roi = cv2.resize(roi, (None), fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
# #
# #                 gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
# #
# #                 _, thresh = cv2.threshold(
# #                     gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
# #                 )
# #
# #                 results = self.ocr_reader.readtext(thresh, allowlist="0123456890")
# #                 text = " ".join([result[1] for result in results])
# #
# #                 extracts.append({"name": region_config["name"], "text": text})
# #
# #                 continue
# #
# #             if region_config["text_extractor"] == TextExtractor.FAB_TEXTBOX:
# #                 # Special handling for textbox
# #                 # 1. Enhance contrast
# #                 gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
# #                 # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
# #                 clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
# #                 enhanced = clahe.apply(gray)
# #
# #                 # 2. Use EasyOCR with paragraph mode
# #                 results = self.ocr_reader.readtext(
# #                     enhanced,
# #                     paragraph=True,  # Treat as a single paragraph
# #                     detail=0,  # Only return the text
# #                     width_ths=0.7,  # Width threshold for text grouping
# #                     add_margin=0.1,  # Add margin to help with text detection
# #                     mag_ratio=1.5,  # Magnification ratio
# #                 )
# #
# #                 # Join the results with newlines since it's a paragraph
# #                 text = "\n".join(results)
# #                 extracts.append({"name": region_config["name"], "text": text})
# #                 continue  # Skip the default text processing below
# #
# #             if region_config["text_extractor"] == TextExtractor.SIMPLE_TITLE:
# #                 results = self.ocr_reader.readtext(roi)
# #                 text = " ".join([result[1] for result in results])
# #                 extracts.append({"name": region_config["name"], "text": text})
# #                 continue
# #
# #             if region_config["text_extractor"] == TextExtractor.FAB_PITCH:
# #                 """
# #                 Count red dots in the pitch region.
# #                 Returns the number of red dots found.
# #                 """
# #                 # Convert to HSV color space for better color detection
# #                 hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
# #
# #                 # Define range for red color in HSV
# #                 # Red wraps around in HSV, so we need two ranges
# #                 lower_red1 = np.array([0, 100, 100])
# #                 upper_red1 = np.array([10, 255, 255])
# #                 lower_red2 = np.array([160, 100, 100])
# #                 upper_red2 = np.array([180, 255, 255])
# #
# #                 # Create masks for red color
# #                 mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
# #                 mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
# #                 red_mask = cv2.bitwise_or(mask1, mask2)
# #
# #                 # Find contours in the mask
# #                 contours, _ = cv2.findContours(
# #                     red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
# #                 )
# #
# #                 # Filter contours based on area and circularity
# #                 red_dots = 0
# #                 for contour in contours:
# #                     area = cv2.contourArea(contour)
# #                     perimeter = cv2.arcLength(contour, True)
# #
# #                     # Avoid division by zero
# #                     if perimeter == 0:
# #                         continue
# #
# #                     # Circularity = 4*pi*area/(perimeter^2)
# #                     circularity = 4 * np.pi * area / (perimeter * perimeter)
# #
# #                     # Adjust these thresholds based on your images
# #                     min_area = 150  # Minimum area of a dot
# #                     max_area = 250  # Maximum area of a dot
# #                     min_circularity = 0.7  # Minimum circularity (1.0 is perfect circle)
# #
# #                     if min_area <= area <= max_area and circularity >= min_circularity:
# #                         red_dots += 1
# #                 extracts.append({"name": region_config["name"], "text": str(red_dots)})
# #
# #         return extracts
